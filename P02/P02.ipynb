{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gmw9PZklM-LK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAkAbckZPC30"
      },
      "source": [
        "### Race Track"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "RYp7_aHeOuVP",
        "outputId": "5d405f5b-53c6-44a5-e8f4-ab5ecbe32ea0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a2680c7f640>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1500x750 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "track = np.zeros(shape=(30, 18))\n",
        "\n",
        "# add race-track weight\n",
        "# columns\n",
        "track[1:26, 2] = 1\n",
        "track[1:, 3] = 1\n",
        "track[:, 4] = 1\n",
        "track[:, 5] = 1\n",
        "track[:, 6] = 1\n",
        "track[:, 7] = 1\n",
        "track[:, 8] = 1\n",
        "\n",
        "track[3:13, 0] = 1\n",
        "track[2:20, 1] = 1\n",
        "track[6, 9] = 1\n",
        "\n",
        "# rows\n",
        "track[0, 4:] = 1\n",
        "track[1, 5:] = 1\n",
        "track[2, 4:] = 1\n",
        "track[3, 4:] = 1\n",
        "track[4, 4:] = 1\n",
        "track[5, 4:] = 1\n",
        "\n",
        "\n",
        "\n",
        "# add beginning\n",
        "track[29, 3:9] = 0.4\n",
        "\n",
        "# add end\n",
        "track[0:6, 17] = 0.8\n",
        "\n",
        "\n",
        "# plot race-track\n",
        "plt.figure(figsize=(10, 5), dpi=150)\n",
        "plt.imshow(track, cmap='GnBu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AdMSMvKUTzQ"
      },
      "source": [
        "### Environments\n",
        "\n",
        "- RaceTrack\n",
        "  - a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEZKnmkMp8p-"
      },
      "outputs": [],
      "source": [
        "class Environment:\n",
        "    def __init__(self, racetrack):\n",
        "        self.racetrack = racetrack\n",
        "        self.done = False\n",
        "        self.action_to_acceleration = {\n",
        "            0: (-1, -1),\n",
        "            1: (-1, 0),\n",
        "            2: (-1, 1),\n",
        "            3: (0, -1),\n",
        "            4: (0, 0),\n",
        "            5: (0, 1),\n",
        "            6: (1, -1),\n",
        "            7: (1, 0),\n",
        "            8: (1, 1)\n",
        "        }\n",
        "\n",
        "    def reset(self):\n",
        "        self.racetrack.reset_car()\n",
        "        self.done = False\n",
        "        return self._get_observation()\n",
        "\n",
        "    def step(self, action):\n",
        "        # Introduce noise with 0.1 probability\n",
        "        if np.random.rand() < 0.1:\n",
        "            acceleration = np.array([0, 0])\n",
        "        else:\n",
        "            acceleration = np.array(self.action_to_acceleration[action])\n",
        "\n",
        "        self.racetrack.update_car(acceleration)\n",
        "\n",
        "        if self.racetrack.check_off_track():\n",
        "            self.racetrack.reset_car()\n",
        "            reward = -1\n",
        "            terminated = False  # Continue the episode after resetting\n",
        "        elif self.racetrack.check_finish_line():\n",
        "            self.done = True\n",
        "            reward = 0\n",
        "            terminated = True\n",
        "        else:\n",
        "            reward = -1\n",
        "            terminated = False\n",
        "\n",
        "        return self._get_observation(), reward, terminated\n",
        "\n",
        "    def _get_observation(self):\n",
        "        return (tuple(self.racetrack.position), tuple(self.racetrack.velocity))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vnnknGP3Ug5Q"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, nA):\n",
        "        self.nA = nA  # Number of possible actions (9 total)\n",
        "\n",
        "    def behavior_policy(self, state_indices, target_pi, epsilon):\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = np.random.randint(self.nA)\n",
        "            prob = 1.0 / self.nA\n",
        "        else:\n",
        "            action = target_pi[state_indices]\n",
        "            prob = 1 - epsilon + (epsilon / self.nA)\n",
        "        return action, prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9xN1KWdp_rd"
      },
      "outputs": [],
      "source": [
        "class RaceTrack:\n",
        "    def __init__(self, track):\n",
        "        self.track = track\n",
        "        self.start_positions = np.argwhere(track == 0.4)\n",
        "        self.finish_line = np.argwhere(track == 0.8)\n",
        "        self.state = None\n",
        "        self.speed = None\n",
        "\n",
        "    def reset_car(self):\n",
        "        # Reset car to a random start position and zero velocity\n",
        "        start_idx = np.random.randint(0, len(self.start_positions))\n",
        "        self.position = self.start_positions[start_idx]  # Random start position\n",
        "        self.velocity = np.array([0, 0])  # Reset velocity to zero\n",
        "\n",
        "    def update_car(self, velocity_change):\n",
        "        # Apply the velocity change to both x and y components\n",
        "        self.velocity = np.clip(self.velocity + velocity_change, 0, 4)\n",
        "        self.position = np.clip(self.position + self.velocity, [0, 0], np.array(self.track.shape) - 1)\n",
        "\n",
        "    def check_off_track(self):\n",
        "        # Return True if car goes off the track (value is 0)\n",
        "        return self.track[self.position[0], self.position[1]] == 0\n",
        "\n",
        "    def check_finish_line(self):\n",
        "        # Return True if car crosses the finish line (value is 0.8)\n",
        "        return self.track[self.position[0], self.position[1]] == 0.8\n",
        "\n",
        "    def render(self):\n",
        "        # Render the racetrack using matplotlib\n",
        "        plt.figure(figsize=(10, 5), dpi=150)\n",
        "        plt.imshow(self.track, cmap='GnBu')\n",
        "\n",
        "        # Plot the car on the racetrack\n",
        "        plt.scatter(self.position[1], self.position[0], color='red', s=100, label='Car')  # Car's position\n",
        "\n",
        "        plt.legend()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D2xs3WqQe9Z"
      },
      "source": [
        "### Behavior Policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SE0VByUQjJV"
      },
      "outputs": [],
      "source": [
        "def off_policy_monte_carlo(total_episodes, racetrack, epsilon=0.1, gamma=0.9):\n",
        "    # Initialize the environment and agent\n",
        "    env = Environment(racetrack)\n",
        "    agent = Agent(nA=9)  # There are 9 possible actions\n",
        "\n",
        "    # Initialize Q, C, and target policy\n",
        "    observation_space = (racetrack.track.shape[0], racetrack.track.shape[1], 9, 9)  # Positions and velocities\n",
        "    Q = np.random.normal(size=(*observation_space, agent.nA))  # Optimistic initialization\n",
        "    Q -= 500  # Optimism in face of uncertainty\n",
        "    C = np.zeros_like(Q)  # For importance sampling correction\n",
        "    target_pi = np.argmax(Q, axis=-1)  # Shape is (rows, cols, 9, 9)\n",
        "\n",
        "    reward_hist = np.zeros(total_episodes)\n",
        "\n",
        "    for i in range(total_episodes):\n",
        "        trajectory = []\n",
        "        terminated = False\n",
        "        state = env.reset()  # Reset environment and get initial state\n",
        "        state_indices = get_state_indices(state)\n",
        "        action, act_prob = agent.behavior_policy(state_indices, target_pi, epsilon)\n",
        "\n",
        "        total_reward = 0\n",
        "        while not terminated:\n",
        "            observation, reward, terminated = env.step(action)\n",
        "            total_reward += reward\n",
        "            trajectory.append((state_indices, action, reward, act_prob))\n",
        "            state = observation\n",
        "            state_indices = get_state_indices(state)\n",
        "            action, act_prob = agent.behavior_policy(state_indices, target_pi, epsilon)\n",
        "\n",
        "        # Backward pass to update Q and target policy using importance sampling\n",
        "        G = 0.0\n",
        "        W = 1.0\n",
        "        while trajectory:\n",
        "            state_indices, action, reward, act_prob = trajectory.pop()\n",
        "            G = gamma * G + reward\n",
        "            C[state_indices][action] += W\n",
        "            Q[state_indices][action] += (W / C[state_indices][action]) * (G - Q[state_indices][action])\n",
        "            target_pi[state_indices] = np.argmax(Q[state_indices])  # Update policy to greedy action\n",
        "\n",
        "            if action != target_pi[state_indices]:\n",
        "                break  # Stop updating if action is not optimal\n",
        "            W *= 1.0 / act_prob  # Update importance sampling weight\n",
        "\n",
        "        reward_hist[i] = total_reward\n",
        "        if i % 100 == 0:\n",
        "            print(f'Episode: {i}, Total Reward: {total_reward}')\n",
        "\n",
        "    return reward_hist, Q, target_pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sj0fQyjiT1rH"
      },
      "outputs": [],
      "source": [
        "def get_state_indices(state):\n",
        "    position = state[0]\n",
        "    velocity = state[1]\n",
        "    row = position[0]\n",
        "    col = position[1]\n",
        "    velocity_x = velocity[0]\n",
        "    velocity_y = velocity[1]\n",
        "    velocity_x_index = velocity_x + 4  # Map from [-4, 4] to [0, 8]\n",
        "    velocity_y_index = velocity_y + 4\n",
        "    return (row, col, velocity_x_index, velocity_y_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqwxo0yRWNb2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import uniform_filter1d\n",
        "\n",
        "# Plot the result\n",
        "def plot_result(reward_hist, total_episodes) -> None:\n",
        "    plt.figure(figsize=(10, 6), dpi=150)\n",
        "    plt.grid(c='lightgray')\n",
        "    plt.margins(0.02)\n",
        "\n",
        "    # Set axis properties\n",
        "    for i, spine in enumerate(plt.gca().spines.values()):\n",
        "        if i in [0, 2]:\n",
        "            spine.set_linewidth(1.5)\n",
        "            continue\n",
        "        spine.set_visible(False)\n",
        "\n",
        "    # Plot raw rewards\n",
        "    x = np.arange(total_episodes)\n",
        "    plt.plot(x, reward_hist, linewidth=1.2, label='Raw Rewards', color='tomato', alpha=0.6)\n",
        "\n",
        "    # Plot smoothed rewards\n",
        "    smoothed_rewards = uniform_filter1d(reward_hist, size=10)  # Use a window size of 10 for smoothing\n",
        "    plt.plot(x, smoothed_rewards, linewidth=1.2, label='Smoothed Rewards', color='cornflowerblue')\n",
        "\n",
        "    # Title and labels\n",
        "    plt.title('Reward History over Episodes', fontsize=12, fontweight='bold')\n",
        "    plt.xlabel('Episodes', fontsize=12, fontweight='bold')\n",
        "    plt.ylabel('Total Reward', fontsize=12, fontweight='bold')\n",
        "\n",
        "    # Show legend and plot\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckZPUiefAn0a"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def simulate_and_plot_trajectories(racetrack, policy, num_trajectories=1):\n",
        "    env = Environment(racetrack)\n",
        "    for trajectory in range(num_trajectories):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(racetrack.track, cmap='GnBu')\n",
        "        positions = [state[0]]  # Store positions to plot\n",
        "        while not done:\n",
        "            state_indices = get_state_indices(state)\n",
        "            action = policy[state_indices]\n",
        "            state, reward, done = env.step(action)\n",
        "            positions.append(state[0])\n",
        "            if done:\n",
        "                break\n",
        "        positions = np.array(positions)\n",
        "        plt.scatter(positions[:, 1], positions[:, 0], c='red', s=10, label='Trajectory {}'.format(trajectory + 1))\n",
        "        plt.title('Trajectory A')\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "qKVJGPMLSGOM",
        "outputId": "d52afc75-860f-4d7e-a9ec-fb4cdc307f3d"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-68e0e8f38191>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Train using Off-policy Monte Carlo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mtotal_episodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moff_policy_monte_carlo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mracetrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-30-456fc2404193>\u001b[0m in \u001b[0;36moff_policy_monte_carlo\u001b[0;34m(total_episodes, racetrack, epsilon, gamma)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtotal_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mtotal_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtrajectory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-9c5ebb44de25>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mterminated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-9c5ebb44de25>\u001b[0m in \u001b[0;36m_get_observation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mracetrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mracetrack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvelocity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Track A\n",
        "track = np.zeros(shape=(30, 18))\n",
        "\n",
        "# add race-track weight\n",
        "# columns\n",
        "track[1:26, 2] = 1\n",
        "track[1:, 3] = 1\n",
        "track[:, 4] = 1\n",
        "track[:, 5] = 1\n",
        "track[:, 6] = 1\n",
        "track[:, 7] = 1\n",
        "track[:, 8] = 1\n",
        "\n",
        "track[3:13, 0] = 1\n",
        "track[2:20, 1] = 1\n",
        "track[6, 9] = 1\n",
        "\n",
        "# rows\n",
        "track[0, 4:] = 1\n",
        "track[1, 5:] = 1\n",
        "track[2, 4:] = 1\n",
        "track[3, 4:] = 1\n",
        "track[4, 4:] = 1\n",
        "track[5, 4:] = 1\n",
        "\n",
        "# add beginning\n",
        "track[29, 3:9] = 0.4\n",
        "\n",
        "# add end\n",
        "track[0:6, 17] = 0.8\n",
        "\n",
        "racetrack = RaceTrack(track)\n",
        "\n",
        "# Train using Off-policy Monte Carlo\n",
        "total_episodes = 10\n",
        "history, Q, pi_t = off_policy_monte_carlo(total_episodes, racetrack)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "fYkxi8peHHxE",
        "outputId": "2c5046e9-5606-42a8-b414-b8e8cb1ac8be"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "simulate_and_plot_trajectories(racetrack, pi_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ncGCsrEEcYM4",
        "outputId": "ea6e3ea4-6efa-496c-cc41-91dfd9bab9ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 0, Total Reward: -425\n",
            "Episode: 100, Total Reward: -83\n",
            "Episode: 200, Total Reward: -27\n",
            "Episode: 300, Total Reward: -42\n",
            "Episode: 400, Total Reward: -30\n",
            "Episode: 500, Total Reward: -22\n",
            "Episode: 600, Total Reward: -34\n",
            "Episode: 700, Total Reward: -9\n",
            "Episode: 800, Total Reward: -51\n",
            "Episode: 900, Total Reward: -27\n",
            "Episode: 1000, Total Reward: -11\n",
            "Episode: 1100, Total Reward: -12\n",
            "Episode: 1200, Total Reward: -11\n",
            "Episode: 1300, Total Reward: -42\n",
            "Episode: 1400, Total Reward: -11\n",
            "Episode: 1500, Total Reward: -20\n",
            "Episode: 1600, Total Reward: -20\n",
            "Episode: 1700, Total Reward: -20\n",
            "Episode: 1800, Total Reward: -17\n",
            "Episode: 1900, Total Reward: -20\n",
            "Episode: 2000, Total Reward: -34\n",
            "Episode: 2100, Total Reward: -10\n",
            "Episode: 2200, Total Reward: -40\n",
            "Episode: 2300, Total Reward: -30\n",
            "Episode: 2400, Total Reward: -23\n",
            "Episode: 2500, Total Reward: -96\n",
            "Episode: 2600, Total Reward: -11\n",
            "Episode: 2700, Total Reward: -19\n",
            "Episode: 2800, Total Reward: -9\n",
            "Episode: 2900, Total Reward: -25\n",
            "Episode: 3000, Total Reward: -18\n",
            "Episode: 3100, Total Reward: -14\n",
            "Episode: 3200, Total Reward: -20\n",
            "Episode: 3300, Total Reward: -10\n",
            "Episode: 3400, Total Reward: -9\n",
            "Episode: 3500, Total Reward: -58\n",
            "Episode: 3600, Total Reward: -12\n",
            "Episode: 3700, Total Reward: -11\n",
            "Episode: 3800, Total Reward: -45\n",
            "Episode: 3900, Total Reward: -11\n",
            "Episode: 4000, Total Reward: -12\n",
            "Episode: 4100, Total Reward: -11\n",
            "Episode: 4200, Total Reward: -41\n",
            "Episode: 4300, Total Reward: -44\n",
            "Episode: 4400, Total Reward: -11\n",
            "Episode: 4500, Total Reward: -10\n",
            "Episode: 4600, Total Reward: -18\n",
            "Episode: 4700, Total Reward: -18\n",
            "Episode: 4800, Total Reward: -40\n",
            "Episode: 4900, Total Reward: -44\n",
            "Episode: 5000, Total Reward: -31\n",
            "Episode: 5100, Total Reward: -21\n",
            "Episode: 5200, Total Reward: -25\n",
            "Episode: 5300, Total Reward: -13\n",
            "Episode: 5400, Total Reward: -11\n",
            "Episode: 5500, Total Reward: -16\n",
            "Episode: 5600, Total Reward: -13\n",
            "Episode: 5700, Total Reward: -11\n",
            "Episode: 5800, Total Reward: -12\n",
            "Episode: 5900, Total Reward: -12\n",
            "Episode: 6000, Total Reward: -26\n",
            "Episode: 6100, Total Reward: -13\n",
            "Episode: 6200, Total Reward: -10\n",
            "Episode: 6300, Total Reward: -22\n",
            "Episode: 6400, Total Reward: -69\n",
            "Episode: 6500, Total Reward: -10\n",
            "Episode: 6600, Total Reward: -18\n",
            "Episode: 6700, Total Reward: -13\n",
            "Episode: 6800, Total Reward: -56\n",
            "Episode: 6900, Total Reward: -28\n",
            "Episode: 7000, Total Reward: -46\n",
            "Episode: 7100, Total Reward: -9\n",
            "Episode: 7200, Total Reward: -10\n",
            "Episode: 7300, Total Reward: -67\n",
            "Episode: 7400, Total Reward: -12\n",
            "Episode: 7500, Total Reward: -11\n",
            "Episode: 7600, Total Reward: -63\n",
            "Episode: 7700, Total Reward: -53\n",
            "Episode: 7800, Total Reward: -31\n",
            "Episode: 7900, Total Reward: -10\n",
            "Episode: 8000, Total Reward: -11\n",
            "Episode: 8100, Total Reward: -10\n",
            "Episode: 8200, Total Reward: -27\n",
            "Episode: 8300, Total Reward: -72\n",
            "Episode: 8400, Total Reward: -34\n",
            "Episode: 8500, Total Reward: -139\n",
            "Episode: 8600, Total Reward: -22\n",
            "Episode: 8700, Total Reward: -10\n",
            "Episode: 8800, Total Reward: -10\n",
            "Episode: 8900, Total Reward: -12\n",
            "Episode: 9000, Total Reward: -10\n",
            "Episode: 9100, Total Reward: -29\n",
            "Episode: 9200, Total Reward: -15\n",
            "Episode: 9300, Total Reward: -10\n",
            "Episode: 9400, Total Reward: -9\n",
            "Episode: 9500, Total Reward: -10\n",
            "Episode: 9600, Total Reward: -12\n",
            "Episode: 9700, Total Reward: -10\n",
            "Episode: 9800, Total Reward: -12\n",
            "Episode: 9900, Total Reward: -42\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAHDCAYAAADhvjXTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApaElEQVR4nO3dfVhUZf4/8PfwNIAwKCAMIwMimCYKtYqomJoSiGZp9uBDBWjmFlbGjyhKNNNdtnA3ykXd/W6JlrpmP5+qDVNKLHyIMDTb9CeECgqYrDACgcac3x9+nXXkyYF7ODPwfl3XuS7OfZ4+g8Pb+9znnBmFJEkSiIgEspG7ACLqfhgsRCQcg4WIhGOwEJFwDBYiEo7BQkTCMViISDgGCxEJx2AhIuEYLAQAiIuLQ//+/eUug7oJBouFUygUtzXt379f7lLbtHnzZmRkZMhdRou2bt2Kxx9/HAMHDoRCocCECRPkLsnqKfiskGX78MMPjeY3btyIvXv34oMPPjBqv+++++Dt7d3h41y7dg16vR5KpbLD+2jL/fffjxMnTuDMmTNm2X9nTJgwAQUFBQgLC0NhYSFCQkIsPqgtnZ3cBVDbHn/8caP5w4cPY+/evc3ab1VfXw9nZ+fbPo69vX2H6pPTb7/9Br1eDwcHh07t54MPPkC/fv1gY2ODoUOHCqquZ+OpUDcwYcIEDB06FAUFBRg3bhycnZ3x6quvAgB27dqFqVOnQqPRQKlUIjAwECtWrEBTU5PRPloaY9Hr9cjIyEBwcDAcHR3h7e2NhQsX4vLly81q+PzzzzF+/Hi4urpCpVIhLCwMmzdvNtT32Wef4ezZs4ZTt5uPdfHiRcyfPx/e3t5wdHREaGgoNmzYYLT/M2fOQKFQYNWqVcjIyEBgYCCUSiW+/fZb9OrVCy+88EKzmsrKymBra4u0tLQ2f39arRY2NvxTEIk9lm6iqqoKMTExmDVrFh5//HHDaVFWVhZcXFyQmJgIFxcXfPnll1i6dCl0Oh3S09Pb3OfChQuRlZWF+Ph4PP/88ygpKcFf//pXfP/998jLyzP0crKysjBv3jwEBwcjJSUFvXv3xvfff4/s7GzMmTMHr732GmpqalBWVoa3334bAODi4gIA+PXXXzFhwgQUFRVh0aJFCAgIwLZt2xAXF4fq6upmgbF+/Xo0NDTg6aefhlKphJ+fH2bMmIGtW7fiL3/5C2xtbQ3rbtmyBZIkYe7cucJ+z3SbJLIqCQkJ0q3/bOPHj5cASOvWrWu2fn19fbO2hQsXSs7OzlJDQ4OhLTY2VvL39zfMf/311xIAadOmTUbbZmdnG7VXV1dLrq6uUnh4uPTrr78aravX6w0/T5061Wj/N2RkZEgApA8//NDQdvXqVWn06NGSi4uLpNPpJEmSpJKSEgmApFKppIsXLxrtY8+ePRIA6fPPPzdqDwkJkcaPH9/smG0JDg42eRtqjv2/bkKpVCI+Pr5Zu5OTk+HnK1eu4NKlS7jnnntQX1+PkydPtrq/bdu2wc3NDffddx8uXbpkmIYPHw4XFxd89dVXAIC9e/fiypUreOWVV+Do6Gi0D4VC0W7d//rXv6BWqzF79mxDm729PZ5//nnU1tYiNzfXaP2ZM2eib9++Rm2RkZHQaDTYtGmToe3EiRM4fvx4u2NRZB48Feom+vXr1+Ig5o8//oglS5bgyy+/hE6nM1pWU1PT6v5Onz6NmpoaeHl5tbj84sWLAIDi4mIA6PCg59mzZzFw4MBmYxx33nmnYfnNAgICmu3DxsYGc+fOxdq1aw2D1ps2bYKjoyMeeeSRDtVFncNg6SZu7pncUF1djfHjx0OlUuGNN95AYGAgHB0dcfToUbz88svQ6/Wt7k+v18PLy8uoF3CzW3sNXaWl1wkATz75JNLT07Fz507Mnj0bmzdvxv333w83N7curpAABku3tn//flRVVWH79u0YN26cob2kpKTdbQMDA7Fv3z5ERES0+sd8Yz3g+qlHUFBQq+u1dlrk7++P48ePQ6/XG/Vabpym+fv7t1srcL3HdPfdd2PTpk3w9fXFuXPnsHr16tvalsTjGEs3duMKiXTTPZBXr17FmjVr2t320UcfRVNTE1asWNFs2W+//Ybq6moAQFRUFFxdXZGWloaGhgaj9W4+bq9evVo89ZoyZQoqKiqwdetWo/2vXr0aLi4uGD9+fLu13vDEE0/giy++QEZGBjw8PBATE3Pb25JY7LF0Y2PGjEGfPn0QGxuL559/HgqFAh988IHRH3xrxo8fj4ULFyItLQ2FhYWIioqCvb09Tp8+jW3btuGdd97Bww8/DJVKhbfffhtPPfUUwsLCMGfOHPTp0wfHjh1DfX294X6U4cOHY+vWrUhMTERYWBhcXFwwbdo0PP300/jb3/6GuLg4FBQUoH///vj444+Rl5eHjIwMuLq63vbrnTNnDpKTk7Fjxw4888wzt33T34EDB3DgwAEAwC+//IK6ujqsXLkSADBu3Dij3h7dJpmvSpGJWrvcHBwc3OL6eXl50qhRoyQnJydJo9FIycnJhsuzX331lWG9Wy833/D3v/9dGj58uOTk5CS5urpKw4YNk5KTk6ULFy4Yrbd7925pzJgxkpOTk6RSqaSRI0dKW7ZsMSyvra2V5syZI/Xu3VsCYHSsyspKKT4+XvL09JQcHBykYcOGSevXrzfa/43Lzenp6W3+fqZMmSIBkA4ePNjmejdbtmyZBKDFadmyZbe9H/ovPitEAK6fRhw6dAhFRUVyl9IpM2bMwA8//GD1r8PacYyFAADl5eXw9PSUu4xOKS8vx2effYYnnnhC7lJ6PI6x9HDHjx/Hzp07ceDAAbz00ktyl9MhJSUlyMvLwz/+8Q/Y29tj4cKFcpfU4zFYerjt27dj9erVmDVrFlJSUuQup0Nyc3MRHx8PPz8/bNiwAWq1Wu6SejyOsRCRcBxjISLhGCxEJJzFjbHo9XpcuHABrq6ut/V0LBF1DUmScOXKFWg0mnY/GMviguXChQvQarVyl0FErSgtLYWvr2+b61hcsNy4hbvozI9wVd3+7dyWyu+BtXKXQNQizzHDTVpf31iP8neevK3HLMwWLJmZmUhPT0dFRQVCQ0OxevVqjBw5st3tbpz+uKquf3aqtVPYOba/EpEMbJS3/2HrN7udIQqzDN7eeNhs2bJlOHr0KEJDQxEdHW34cCAi6t7MEix/+ctfsGDBAsTHx2PIkCFYt24dnJ2d8f7775vjcEStCtOVYXbFMYTpyuQuxYil1gUAd50/iYeO5+Cu861/dGl7hJ8KXb16FQUFBUZ3cdrY2CAyMhKHDh0SfTiiVq0o/gJJpXmG+VXaCKQGRslY0XWWWhcAvJLzPp49+LFhfs2Yh/GnSfNM3o/wHsulS5fQ1NTU7Fv5vL29UVFR0Wz9xsZG6HQ6o4mos8J0ZUZ/vACQVJonew/BUusCrvdUbg4VAHj24Mcd6rnIfoNcWloa3NzcDBMvNZMIQfVVJrV3FUutCwAGVJ03qb0twoPF09MTtra2qKysNGqvrKxs8eGwlJQU1NTUGKbS0lLRJVEPVOTsYVJ7V7HUugDgZ49+JrW3RXiwODg4YPjw4cjJyTG06fV65OTkYPTo0c3WVyqVUKlURhNRZ+WrfLFKG2HUlq4di3xV2zd2mZul1gUAhf0GY82Yh43aMsc8gsJ+g03el1nuY0lMTERsbCxGjBiBkSNHIiMjA3V1dS1+oRaRuaQGRmF33yEIqq9CkbOHRfzxApZbFwD8adI8ZA8egwFV5/GzR78OhQpgpmB57LHH8Msvv2Dp0qWoqKjAXXfdhezs7GYDukTmlq/ytag/3BsstS7ges+lo4Fyg9nuvF20aBEWLVpkrt0TkQWzuGeFulKfyHfkLoGoW5L9cjMRdT8MFiISjsFCRML16DEWEiNMV2aRl05JPgwW6hRLfqCO5MNTIeowS36gjuTFYKEOs+QH6kheDBbqMEt+oI7kxWChDrPkB+pIXhy8pU6x5AfqSD4MFuo0S36gjuTBUyEiEq7b9Fj4QCGR5WCPhYiEY7AQkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEs5inxXye2AtFHaOcpdBRB3AHgsRCcdgISLhGCxEJByDhYiEY7AQkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEo7BQkTCMViISDiL/aAnEiNMV4ag+ioUOXsgX+UrdznUQzBYurEVxV8gqTTPML9KG4HUwCgZK6KegqdC3VSYrswoVAAgqTQPYboymSqinoTB0k0F1VeZ1E4kEoOlmypy9jCpnUgkBks3la/yxSpthFFbunYsB3CpS3DwthtLDYzC7r5DeFWIuhyDpZvLV/kyUKjL8VSIiIRjsBCRcAwWIhJOeLC8/vrrUCgURtPgwYNFH4aILJhZBm+Dg4Oxb9++/x7EjmPERD2JWf7i7ezsoFarzbFrIrICZhljOX36NDQaDQYMGIC5c+fi3Llz5jgMEVko4T2W8PBwZGVlYdCgQSgvL8fy5ctxzz334MSJE3B1dW22fmNjIxobGw3zOp1OdElE1MWEB0tMTIzh55CQEISHh8Pf3x8fffQR5s+f32z9tLQ0LF++XHQZRCQjs19u7t27N+644w4UFRW1uDwlJQU1NTWGqbS01NwlEZGZmT1YamtrUVxcDB8fnxaXK5VKqFQqo4mIrJvwYElKSkJubi7OnDmDgwcPYsaMGbC1tcXs2bNFH4qILJTwMZaysjLMnj0bVVVV6Nu3L8aOHYvDhw+jb9++og9FRBZKeLD885//FL1LIrIyvCWWLM7lfS/IXQK1QKfTwfut21uXDyESkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEo7BQkTCMViISDg+hEhmxQcKeyb2WIhIOAYLEQnHYCEi4TjGIpMwXRmC6qtQ5OyBfJWv3OUQCcVgkcGK4i+QVJpnmF+ljUBqYJSMFRGJxVOhLhamKzMKFQBIKs1DmK5MpoqIxGOwdLGg+iqT2omsEYOlixU5e5jUTmSNGCxdLF/li1XaCKO2dO1YDuBSt8LBWxmkBkZhd98hvCpE3RaDRSb5Kl8GCnVbPBUiIuEYLEQkHIOFiIRjsBCRcAwWIhKOwUJEwjFYiEg4BgsRCcdgISLhGCxEJByDhYiEY7AQkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEo7BQkTCMViISDgGCxEJx2AhIuEYLEQkHIOFiIRjsBCRcAwWIhLO5GA5cOAApk2bBo1GA4VCgZ07dxotlyQJS5cuhY+PD5ycnBAZGYnTp0+LqpeIrIDJwVJXV4fQ0FBkZma2uPytt97Cu+++i3Xr1uHIkSPo1asXoqOj0dDQ0Oliicg62Jm6QUxMDGJiYlpcJkkSMjIysGTJEjz44IMAgI0bN8Lb2xs7d+7ErFmzOlctEVkFoWMsJSUlqKioQGRkpKHNzc0N4eHhOHToUIvbNDY2QqfTGU1EZN2EBktFRQUAwNvb26jd29vbsOxWaWlpcHNzM0xarVZkSUQkA9mvCqWkpKCmpsYwlZaWyl0SEXWS0GBRq9UAgMrKSqP2yspKw7JbKZVKqFQqo4mIrJvQYAkICIBarUZOTo6hTafT4ciRIxg9erTIQxGRBTP5qlBtbS2KiooM8yUlJSgsLIS7uzv8/PywePFirFy5EgMHDkRAQABSU1Oh0Wgwffp0kXUTkQUzOVi+++473HvvvYb5xMREAEBsbCyysrKQnJyMuro6PP3006iursbYsWORnZ0NR0dHcVUTkUVTSJIkyV3EzXQ6Hdzc3KAcmwKFHcPI2l3e94LcJZAgOp0O3u5+qKmpaXcsVParQkTU/TBYiEg4BgsRCWfy4C01F6YrQ1B9FYqcPZCv8pW7HCLZMVg6aUXxF0gqzTPMr9JGIDUwSsaKiOTHU6FOCNOVGYUKACSV5iFMVyZTRUSWgcHSCUH1VSa1E/UUDJZOKHL2MKmdqKdgsHRCvsoXq7QRRm3p2rEcwKUej4O3nZQaGIXdfYfwqhDRTRgsAuSrfBkoRDfhqRARCcdgISLhGCxEJByDhYiEY7AQkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEs5iPzbh3O5n2v22tZv1iXzHjNUQkSnYYyEi4RgsRCQcg4WIhGOwEJFwDBYiEo7BQkTCMViISDgGCxEJx2AhIuEYLEQkHIOFiIRjsBCRcAwWIhKOwUJEwjFYiEg4BgsRCcdgISLhGCxEJByDhYiEY7AQkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhDM5WA4cOIBp06ZBo9FAoVBg586dRsvj4uKgUCiMpsmTJ4uql4isgMnBUldXh9DQUGRmZra6zuTJk1FeXm6YtmzZ0qkiLV2YrgyzK44hTFcmdylEFsHO1A1iYmIQExPT5jpKpRJqtbrDRVmTFcVfIKk0zzC/ShuB1MAoGSsikp9Zxlj2798PLy8vDBo0CM888wyqqqpaXbexsRE6nc5oshZhujKjUAGApNI89lyoxxMeLJMnT8bGjRuRk5ODN998E7m5uYiJiUFTU1OL66elpcHNzc0wabVa0SWZTVB9y4HZWjtRT2HyqVB7Zs2aZfh52LBhCAkJQWBgIPbv349JkyY1Wz8lJQWJiYmGeZ1OZzXhUuTsYVI7UU9h9svNAwYMgKenJ4qKilpcrlQqoVKpjCZrka/yxSpthFFbunYs8lW+MlVEZBmE91huVVZWhqqqKvj4+Jj7ULJIDYzC7r5DEFRfhSJnD4YKEToQLLW1tUa9j5KSEhQWFsLd3R3u7u5Yvnw5Zs6cCbVajeLiYiQnJyMoKAjR0dFCC7ck+SpfBgrRTUwOlu+++w733nuvYf7G+EhsbCzWrl2L48ePY8OGDaiuroZGo0FUVBRWrFgBpVIprmoismgmB8uECRMgSVKry/fs2dOpgojI+vFZISISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEo7BQkTCMViISDgGCxEJx2AhIuEYLEQkHIOFiIRjsBCRcAwWIhKOwUJEwjFYiEg4BgsRCcdgISLhGCxEJByDhYiEY7AQkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEo7BQkTCMViISDgGCxEJx2AhIuEYLEQkHIOFiIRjsBCRcAwWIhKOwUJEwtnJXUB3EKYrQ1B9FYqcPZCv8pW7HCLZMVg6aUXxF0gqzTPMr9JGIDUwSsaKiOTHU6FOCNOVGYUKACSV5iFMVyZTRUSWgcHSCUH1VSa1E/UUDJZOKHL2MKmdqKdgsHRCvsoXq7QRRm3p2rEcwKUej4O3nZQaGIXdfYfwqhDRTRgsAuSrfBkoRDfhqRARCddteiyX971g8jZ9It8xQyVExB4LEQlnUrCkpaUhLCwMrq6u8PLywvTp03Hq1CmjdRoaGpCQkAAPDw+4uLhg5syZqKysFFo0EVk2k4IlNzcXCQkJOHz4MPbu3Ytr164hKioKdXV1hnVefPFFfPLJJ9i2bRtyc3Nx4cIFPPTQQ8ILJyLLZdIYS3Z2ttF8VlYWvLy8UFBQgHHjxqGmpgbvvfceNm/ejIkTJwIA1q9fjzvvvBOHDx/GqFGjxFVORBarU2MsNTU1AAB3d3cAQEFBAa5du4bIyEjDOoMHD4afnx8OHTrU4j4aGxuh0+mMJiKybh0OFr1ej8WLFyMiIgJDhw4FAFRUVMDBwQG9e/c2Wtfb2xsVFRUt7ictLQ1ubm6GSavVdrQkIrIQHQ6WhIQEnDhxAv/85z87VUBKSgpqamoMU2lpaaf2R0Ty69B9LIsWLcKnn36KAwcOwNf3v3ecqtVqXL16FdXV1Ua9lsrKSqjV6hb3pVQqoVQqO1IGEVkok3oskiRh0aJF2LFjB7788ksEBAQYLR8+fDjs7e2Rk5NjaDt16hTOnTuH0aNHi6mYiCyeST2WhIQEbN68Gbt27YKrq6th3MTNzQ1OTk5wc3PD/PnzkZiYCHd3d6hUKjz33HMYPXo0rwgR9SAmBcvatWsBABMmTDBqX79+PeLi4gAAb7/9NmxsbDBz5kw0NjYiOjoaa9asEVIsEVkHk4JFkqR213F0dERmZiYyMzM7XBQRWTc+K0REwjFYiEg4BgsRCcdgISLhGCxEJByDhYiEY7AQkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEo7BQkTCMViISDgGCxEJx2AhIuEYLEQkHIOFiIRjsBCRcAwWIhKOwUJEwjFYiEg4BgsRCcdgISLhGCxEJJyd3AX0VGG6MgTVV6HI2QP5Kl+5yyESisEigxXFXyCpNM8wv0obgdTAKBkrIhKLp0JdLExXZhQqAJBUmocwXZlMFRGJx2DpYkH1VSa1E1kjBksXK3L2MKmdyBoxWLpYvsoXq7QRRm3p2rEcwKVuhYO3MkgNjMLuvkN4VYi6LQaLTPJVvgwU6rZ4KkREwjFYiEg4BgsRCcdgISLhGCxEJByDhYiEY7AQkXAMFiISjsFCRMIxWIhIOAYLEQnHYCEi4RgsRCQcg4WIhGOwEJFwDBYiEs6kYElLS0NYWBhcXV3h5eWF6dOn49SpU0brTJgwAQqFwmj6/e9/L7RoIrJsJgVLbm4uEhIScPjwYezduxfXrl1DVFQU6urqjNZbsGABysvLDdNbb70ltGgismwmfTRldna20XxWVha8vLxQUFCAcePGGdqdnZ2hVqvFVEhEVqdTYyw1NTUAAHd3d6P2TZs2wdPTE0OHDkVKSgrq6+s7cxgisjId/jBtvV6PxYsXIyIiAkOHDjW0z5kzB/7+/tBoNDh+/DhefvllnDp1Ctu3b29xP42NjWhsbDTM63S6jpZERBaiw8GSkJCAEydO4JtvvjFqf/rppw0/Dxs2DD4+Ppg0aRKKi4sRGBjYbD9paWlYvnx5R8sgIgvUoVOhRYsW4dNPP8VXX30FX9+2v8IiPDwcAFBUVNTi8pSUFNTU1Bim0tLSjpRERBbEpB6LJEl47rnnsGPHDuzfvx8BAQHtblNYWAgA8PHxaXG5UqmEUqk0pQwisnAmBUtCQgI2b96MXbt2wdXVFRUVFQAANzc3ODk5obi4GJs3b8aUKVPg4eGB48eP48UXX8S4ceMQEhJilhdARJbHpGBZu3YtgOs3wd1s/fr1iIuLg4ODA/bt24eMjAzU1dVBq9Vi5syZWLJkibCCicjymXwq1BatVovc3NxOFURE1q9Hf3fz5X0vmLR+n8h3zFQJUffChxCJSDgGCxEJ16NPhaxNmK4MQfVVKHL2QL6q7fuHiOTEYLESK4q/QFJpnmF+lTYCqYFRMlZE1DqeClmBMF2ZUagAQFJpHsJ0ZTJVRNQ2BosVCKqvMqmdSG4MFitQ5OxhUjuR3BgsViBf5YtV2gijtnTtWA7gksXi4K2VSA2Mwu6+Q3hViKwCg8WK5Kt8GShkFXgqRETCMViISDgGCxEJx2AhIuEYLEQkHIOFiIRjsBCRcLyPhQyclLbwdHWEQiFun40NV8XtjMxLAdjb28PGpvNvAAYLQaEAnpgYhKnhfnCwsxUaLOfPXhS3MzI7hQ3g66+GvUPnooHBQnhiYhAeHR+E3n3cARt7iEyW/v3d21+JLIJeL6H8Qjl+qfwPfHz7QtGJ9wGDpYdzVtpharjf9VCxdxa+f0dHR+H7JPPp6+WJC+fL0dSkh52dbYf3w8HbHs7DVQkHO9vrPRXq8eztHQAATb81dWo/DJYeTqH43zMfkQMrZLVEvQ0YLEQkHIOF6CYT752EFxcnyl2G1WOwkFWytbFvc1r++hsd2u/H/3cb3lixXFidcgdVQ0MD4uPnITTkLjjYO2LGjJldclxeFSKrdP5CqeHnj7Z+hGXLluOnkz8a2lxcXAw/S5KEpqYm2Nm1/3Z3d7fMy+NXr16Fg4ODyds1NTXBydEJi55bhO3bd5ihspaxx0JWSa1WGyaVmxsUCoVh/uTJU3BT9cHnn2cjbMRIODn2wjff5KG4uBjTpz8EH3U/qFx7I3zkKOzbl2O031t7GI2NjXgpKRlaX3+4urhh9Kgx2L8/12ibvLw8TLx3Elx6qeDh3heTJ0/B5cuXER8/D7m5B/Duu6sNPakzZ84AAHJzD2BU+Gg4OfZCP40WKa+8it9++82ojucWPY8XFyfCq68aMZOnYP68pzBt2oNGx7527RrU3hq89977Lf6eevXqhTVrM7FgwVNQq7078ys3CYPFioTpyjC74phFf5+Q87GjcN/1MZyPHZW7FLya8ir+mPZH/PjvHxASMgy1tbWIiZmMvfv2oOBoPqKjo/HgA9Nx7ty5Vvfx3KLncfjwYWzesgmFx47i4YcfxpSYqTh9+jQAoLCwEPdFRuPOO+9E3sGvceDr/Zh2/1Q0NTUhI+NtjB49Ck89NR/nL5Ti/IVSaLVanD9/HvdPnYYRI0bg+8ICZK75K95/fz3+sPKPRsfeuPEDODg44OtvcrFmbSbmPzUPe7L3oLy83LDOp59+hvr6ejz22KNm+R12FE+FrIQ1fBNiv1V/gPofawzzFU89C/z9HdnqeX3567jvvkjDvLu7O0JDQw3zb6xYjp07d+GT3Z8gYVFCs+3PnTuHrKwNOHP2Z2g0GgDA/0lKxJ49e5C1fgP+8MeVSE//M0aMGI7MNX81bBccHGz42cHBAc7OzlCr1Ya2tWvWQavVYvVf34VCocDgwYNRfuECXnnlVaQuXQIbm+v/3w8cGIQ33/qTUU2DBg3Chx9swkvJSQCArKwNePiRmUanfpaAPRYrYA3fhOh87KhRqAC4Pn/kiEwVASNGDDear62txUtJyQgeMgzufTyhcu2Nn376CefOlba4/Q8/nEBTUxMGDxoClWtvw5SbewDFP/8MADhWeAwTJ040qa6fTp7EqNHhRrfMj4kYg9raWpSV/fff9He/+12zbefPj0dW1gYAQGVlJbI/z0Z8fLxJx+8K7LFYgba+CdFSPrXf8czPLS/4f6eB8PCuLeZ/9erVy2j+paRk7NuXg7fS30RQUCCcnJzw6COP4erVlp/Arq2tha2tLfK/OwJbW+Pb22/0EJyczPfIwq31A8ATTz6BlJTXcOjQIRw6eBgBAQG4556xZquhoxgsVsAavgmxof+AlhfcMbBrC2nDwYMHERv7JGbMmA7genCcOXMW48e3vP7dd9+FpqYmXLz4S6t/vMNChuHLL7/E68uXtbjc3sEBTU3Gt8ffOXgwtm/fAUmSDL2Wg3kH4erqCl/ftv+j8PDwwIPTH0TW+g04fPgw4uJi21xfLjwVsgLW8E2I9aG/uz6mcpPyBQmy9VZaEjRwIHbs2IHCwkIcO3YMc+c+Ab1e3+r6d9xxB+bMnY242Hhs374DJSUl+Pbbb/GntDfx2Wf/AgC88srLyM//DgnPLsLx48dx8uRJrF27DpcuXQIA9Pf3x7fffoszZ87g0qVL0Ov1eObZ36O0tBTPP/cCTp48iV27duP119/Aiy8uNoyvtGX+/HnYuPED/PTTSTwZ+0S76//73/9GYWEh/vOfy9DV1KCwsBCFhYW390vrIPZYrIQ1fBPi+aTXcPm+GDie+RkN/QegPvR36LoLnO3785/T8dT8BRgbMQ6enp5ITk7CFZ2uzW3ef/89/GHlH/FSUjLOnz8PT09PhI8Kx9T7pwC4Hj7Zez7HkteWYFT4GDg5OWFk+EjMnj0LwPXB3vi4eRgaHIJff/0VxT+fRv/+/fHpZ5/g5eSXcfddw+Hu7o558+Lx2pJXb+t1REZOgo+PD4YEDzEMKrfl/qkP4OzZs4b54b8LAwA06a/d1vE6QiFJkmS2vXeATqeDm5sbKv9zDiqVSu5yjPSJlO8Kh7n49e2Fd58dA0/vfoCN+P9n7r7DS/g+zSlizFhMnDgRK1Z27M7drlBbWwutrz/ee/8feOihGUL33dDQgDMlZ9HP3wtKR+Mb8nQ6Hbzd/VBTU9Pu3yZPhYhw/Ua47777Dj/++G8MCR4idzkt0uv1uHjxIlau+AN69+6NBx6YJndJreKpkAnW/s1yxgtEUTbZwv2aEhqNE+yVpt8y3l18/nk24mLjMe2B+/Hww13zPI2pzp07h8ABA+Hr64v31793W48oyMVyKyPqQtOnP4jqmv/IXUab+vfvb9ZxEZF4KkREwjFYiEg4ngoJ4HnsJFQlZdAF+OJS6GCzbWMOkuL6RUFJb1EXB0kmoi4SM1g6afiq9zDsf7YZ5n9Y8AgKkuYL38Zcrin0uCr9hqrKX9Dbsw9s7ew69bUPt2qQOv5J79S1JElC1aX/AArAzp7fKyQbz2MnjQICAIb9zzacvS+i1V5IR7YxJ0kBlChroL56DfXnG2Aj+EO1L9sphe6PzEwBqPt5wta2c6MkDJZOUJW0/HSxqqSs1ZDoyDbm9puNHmXKWthKdbCFAgpJXLhM8QttfyWyGHb2dp0OFYDB0im6gJZvq2+tvaPbdAkF0KSQ0ASxYy233r1JPQOvCnXCpdDB+GHBI0Ztxxc82mbPoyPbEFkb9lg6qSBpPs7eF2HSFZ6ObENkTRgsAlwKHWxyOHRkGyJrYXHBcuM6+hXdFZkrae7X2jq5S7A6unY+loCsx42/ydu518XiguXKlevFB/UPbmdNsgbPtr8KWZkrV67Azc2tzXUs7vNY9Ho9Lly4AFdX12Y3aul0Omi1WpSWllrcZ7V0Bb5+vn45X78kSbhy5Qo0Gk27n3RncT0WGxubdj/3U6VS9cg31g18/Xz9cr3+9noqN/ByMxEJx2AhIuGsKliUSiWWLVsGpbJnPn/C18/Xby2v3+IGb4nI+llVj4WIrAODhYiEY7AQkXAMFiISzmqCJTMzE/3794ejoyPCw8Px7bffyl1Sl3n99dehUCiMpsGDu+8DjAcOHMC0adOg0WigUCiwc+dOo+WSJGHp0qXw8fGBk5MTIiMjcfr0aXmKNYP2Xn9cXFyz98PkyZPlKbYVVhEsW7duRWJiIpYtW4ajR48iNDQU0dHRuHjxotyldZng4GCUl5cbpm+++Ubuksymrq4OoaGhyMzMbHH5W2+9hXfffRfr1q3DkSNH0KtXL0RHR6OhoaGLKzWP9l4/AEyePNno/bBly5YurPA2SFZg5MiRUkJCgmG+qalJ0mg0UlpamoxVdZ1ly5ZJoaGhcpchCwDSjh07DPN6vV5Sq9VSenq6oa26ulpSKpXSli1bZKjQvG59/ZIkSbGxsdKDDz4oSz23y+J7LFevXkVBQQEiIyMNbTY2NoiMjMShQ4dkrKxrnT59GhqNBgMGDMDcuXNx7tw5uUuSRUlJCSoqKozeD25ubggPD+9R74f9+/fDy8sLgwYNwjPPPIOqqiq5SzJi8cFy6dIlNDU1wdvb26jd29sbFRUVMlXVtcLDw5GVlYXs7GysXbsWJSUluOeeewwfMdGT3Pg378nvh8mTJ2Pjxo3IycnBm2++idzcXMTExKCpqUnu0gws7ulmai4mJsbwc0hICMLDw+Hv74+PPvoI8+fL831EJJ9Zs2YZfh42bBhCQkIQGBiI/fv3Y9KkSTJW9l8W32Px9PSEra0tKisrjdorKyuhVqtlqkpevXv3xh133IGioiK5S+lyN/7N+X74rwEDBsDT09Oi3g8WHywODg4YPnw4cnJyDG16vR45OTkYPXq0jJXJp7a2FsXFxfDx8ZG7lC4XEBAAtVpt9H7Q6XQ4cuRIj30/lJWVoaqqyqLeD1ZxKpSYmIjY2FiMGDECI0eOREZGBurq6hAfHy93aV0iKSkJ06ZNg7+/Py5cuIBly5bB1tYWs2fPlrs0s6itrTX637ekpASFhYVwd3eHn58fFi9ejJUrV2LgwIEICAhAamoqNBoNpk+fLl/RArX1+t3d3bF8+XLMnDkTarUaxcXFSE5ORlBQEKKjo2Ws+hZyX5a6XatXr5b8/PwkBwcHaeTIkdLhw4flLqnLPPbYY5KPj4/k4OAg9evXT3rsscekoqIiucsym6+++koC0GyKjY2VJOn6JefU1FTJ29tbUiqV0qRJk6RTp07JW7RAbb3++vp6KSoqSurbt69kb28v+fv7SwsWLJAqKirkLtsIPzaBiISz+DEWIrI+DBYiEo7BQkTCMViISDgGCxEJx2AhIuEYLEQkHIOFiIRjsBCRcAwWIhKOwUJEwjFYiEi4/w/0fMHODy737QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import uniform_filter1d\n",
        "\n",
        "\n",
        "\n",
        "class Environment:\n",
        "    def __init__(self, racetrack):\n",
        "        self.racetrack = racetrack\n",
        "        self.done = False\n",
        "        self.action_to_acceleration = {\n",
        "            0: (-1, -1),\n",
        "            1: (-1, 0),\n",
        "            2: (-1, 1),\n",
        "            3: (0, -1),\n",
        "            4: (0, 0),\n",
        "            5: (0, 1),\n",
        "            6: (1, -1),\n",
        "            7: (1, 0),\n",
        "            8: (1, 1)\n",
        "        }\n",
        "\n",
        "    def reset(self):\n",
        "        self.racetrack.reset_car()\n",
        "        self.done = False\n",
        "        return self._get_observation()\n",
        "\n",
        "    def step(self, action):\n",
        "        # Introduce noise with 0.1 probability\n",
        "        if np.random.rand() < 0.1:\n",
        "            acceleration = np.array([0, 0])\n",
        "        else:\n",
        "            acceleration = np.array(self.action_to_acceleration[action])\n",
        "\n",
        "        self.racetrack.update_car(acceleration)\n",
        "\n",
        "        if self.racetrack.check_off_track():\n",
        "            self.racetrack.reset_car()\n",
        "            reward = -1\n",
        "            terminated = False  # Continue the episode after resetting\n",
        "        elif self.racetrack.check_finish_line():\n",
        "            self.done = True\n",
        "            reward = 0\n",
        "            terminated = True\n",
        "        else:\n",
        "            reward = -1\n",
        "            terminated = False\n",
        "\n",
        "        return self._get_observation(), reward, terminated\n",
        "\n",
        "    def _get_observation(self):\n",
        "        return (tuple(self.racetrack.position), tuple(self.racetrack.velocity))\n",
        "\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self, nA):\n",
        "        self.nA = nA  # Number of possible actions (9 total)\n",
        "\n",
        "    def behavior_policy(self, state_indices, target_pi, epsilon):\n",
        "        if np.random.rand() < epsilon:\n",
        "            action = np.random.randint(self.nA)\n",
        "            prob = 1.0 / self.nA\n",
        "        else:\n",
        "            action = target_pi[state_indices]\n",
        "            prob = 1 - epsilon + (epsilon / self.nA)\n",
        "        return action, prob\n",
        "\n",
        "\n",
        "class RaceTrack:\n",
        "    def __init__(self, track):\n",
        "        self.track = track\n",
        "        self.start_positions = np.argwhere(track == 0.4)\n",
        "        self.finish_line = np.argwhere(track == 0.8)\n",
        "        self.state = None\n",
        "        self.speed = None\n",
        "\n",
        "    def reset_car(self):\n",
        "        # Reset car to a random start position and zero velocity\n",
        "        start_idx = np.random.randint(0, len(self.start_positions))\n",
        "        self.position = self.start_positions[start_idx]  # Random start position\n",
        "        self.velocity = np.array([0, 0])  # Reset velocity to zero\n",
        "\n",
        "    def update_car(self, velocity_change):\n",
        "        # Apply the velocity change to both x and y components\n",
        "        self.velocity = np.clip(self.velocity + velocity_change, -4, 4)  # Allow negative velocities\n",
        "        self.position = np.clip(self.position + self.velocity, [0, 0], np.array(self.track.shape) - 1)\n",
        "\n",
        "    def check_off_track(self):\n",
        "        # Return True if car goes off the track (value is 0)\n",
        "        return self.track[self.position[0], self.position[1]] == 0\n",
        "\n",
        "    def check_finish_line(self):\n",
        "        # Return True if car crosses the finish line (value is 0.8)\n",
        "        return self.track[self.position[0], self.position[1]] == 0.8\n",
        "\n",
        "    def render(self):\n",
        "        # Render the racetrack using matplotlib\n",
        "        plt.figure(figsize=(10, 5), dpi=150)\n",
        "        plt.imshow(self.track, cmap='GnBu')\n",
        "\n",
        "        # Plot the car on the racetrack\n",
        "        plt.scatter(self.position[1], self.position[0], color='red', s=100, label='Car')  # Car's position\n",
        "\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class OffPolicyMonteCarlo:\n",
        "    def __init__(self, racetrack, total_episodes, epsilon=0.1, gamma=0.9):\n",
        "        self.racetrack = racetrack\n",
        "        self.total_episodes = total_episodes\n",
        "        self.epsilon = epsilon\n",
        "        self.gamma = gamma\n",
        "        self.env = Environment(racetrack)\n",
        "        self.agent = Agent(nA=9)  # Assuming there are 9 possible actions\n",
        "\n",
        "        # Initialize Q, C, and target policy\n",
        "        observation_space = (racetrack.track.shape[0], racetrack.track.shape[1], 9, 9)\n",
        "        self.Q = np.random.normal(size=(*observation_space, self.agent.nA))\n",
        "        self.Q -= 500  # Optimism in face of uncertainty\n",
        "        self.C = np.zeros_like(self.Q)\n",
        "        self.target_pi = np.argmax(self.Q, axis=-1)\n",
        "\n",
        "    def get_state_indices(self, state):\n",
        "        position, velocity = state\n",
        "        row, col = position\n",
        "        velocity_x, velocity_y = velocity\n",
        "        velocity_x_index = velocity_x + 4\n",
        "        velocity_y_index = velocity_y + 4\n",
        "        return (row, col, velocity_x_index, velocity_y_index)\n",
        "\n",
        "    def train(self):\n",
        "        reward_hist = np.zeros(self.total_episodes)\n",
        "        for i in range(self.total_episodes):\n",
        "            trajectory = []\n",
        "            terminated = False\n",
        "            state = self.env.reset()\n",
        "            state_indices = self.get_state_indices(state)\n",
        "            action, act_prob = self.agent.behavior_policy(state_indices, self.target_pi, self.epsilon)\n",
        "\n",
        "            total_reward = 0\n",
        "            while not terminated:\n",
        "                observation, reward, terminated = self.env.step(action)\n",
        "                total_reward += reward\n",
        "                trajectory.append((state_indices, action, reward, act_prob))\n",
        "                state = observation\n",
        "                state_indices = self.get_state_indices(state)\n",
        "                action, act_prob = self.agent.behavior_policy(state_indices, self.target_pi, self.epsilon)\n",
        "\n",
        "            # Update Q-values and policy via backward pass (importance sampling)\n",
        "            G = 0.0\n",
        "            W = 1.0\n",
        "            for state_indices, action, reward, act_prob in reversed(trajectory):\n",
        "                G = self.gamma * G + reward\n",
        "                self.C[state_indices][action] += W\n",
        "                self.Q[state_indices][action] += (W / self.C[state_indices][action]) * (G - self.Q[state_indices][action])\n",
        "                self.target_pi[state_indices] = np.argmax(self.Q[state_indices])\n",
        "\n",
        "                if action != self.target_pi[state_indices]:\n",
        "                    break\n",
        "                W /= act_prob\n",
        "\n",
        "            reward_hist[i] = total_reward\n",
        "            if i % 100 == 0:\n",
        "                print(f'Episode: {i}, Total Reward: {total_reward}')\n",
        "\n",
        "        return reward_hist, self.Q, self.target_pi\n",
        "\n",
        "    def simulate_and_plot_trajectories(self, num_trajectories=1):\n",
        "        for trajectory in range(num_trajectories):\n",
        "            state = self.env.reset()\n",
        "            done = False\n",
        "            positions = [state[0]]\n",
        "            while not done:\n",
        "                state_indices = self.get_state_indices(state)\n",
        "                action = self.target_pi[state_indices]\n",
        "                state, reward, done = self.env.step(action)\n",
        "                positions.append(state[0])\n",
        "\n",
        "            positions = np.array(positions)\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.imshow(self.racetrack.track, cmap='GnBu')\n",
        "            plt.scatter(positions[:, 1], positions[:, 0], c='red', s=10, label=f'Trajectory {trajectory + 1}')\n",
        "            plt.title('Trajectory {}'.format(trajectory + 1))\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "\n",
        "def trackA():\n",
        "    track = np.zeros(shape=(30, 18))\n",
        "    track[1:26, 2] = 1\n",
        "    track[1:, 3] = 1\n",
        "    track[:, 4] = 1\n",
        "    track[:, 5] = 1\n",
        "    track[:, 6] = 1\n",
        "    track[:, 7] = 1\n",
        "    track[:, 8] = 1\n",
        "    track[3:13, 0] = 1\n",
        "    track[2:20, 1] = 1\n",
        "    track[6, 9] = 1\n",
        "    track[0, 4:] = 1\n",
        "    track[1, 5:] = 1\n",
        "    track[2, 4:] = 1\n",
        "    track[3, 4:] = 1\n",
        "    track[4, 4:] = 1\n",
        "    track[5, 4:] = 1\n",
        "    track[29, 3:9] = 0.4\n",
        "    track[0:6, 17] = 0.8\n",
        "\n",
        "    racetrack = RaceTrack(track)\n",
        "    monte_carlo = OffPolicyMonteCarlo(racetrack, total_episodes=10000)\n",
        "    reward_history, Q_values, policy = monte_carlo.train()\n",
        "    monte_carlo.simulate_and_plot_trajectories(num_trajectories=1)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    trackA()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaGfcl3nJryn",
        "outputId": "d201e34e-a6e1-4dc0-865d-9fd9543fada7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 20000/20000 [00:46<00:00, 425.97it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 602.09it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 588.73it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 622.36it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 624.94it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 623.40it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 622.65it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 635.42it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 618.69it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 626.12it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 631.34it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 617.04it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 609.29it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 603.09it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 628.12it/s]\n",
            "100%|| 20000/20000 [00:35<00:00, 556.43it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 618.83it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 625.85it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 630.97it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 622.78it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 611.93it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 608.44it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 621.90it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 594.09it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 601.11it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 599.05it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 610.35it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 590.97it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 598.71it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 607.43it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 618.68it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 619.34it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 598.75it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 619.20it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 627.10it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 631.99it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 633.48it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 621.21it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 643.06it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 630.68it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 656.81it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 621.47it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 642.28it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 637.56it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 635.94it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 645.36it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 633.42it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 638.17it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 631.16it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 634.99it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 656.58it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 645.99it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 646.10it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 643.65it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 629.87it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 656.18it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 638.10it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 644.65it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 639.43it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 651.65it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 603.24it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 623.40it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 623.06it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 613.56it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 608.76it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 606.09it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 627.43it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 616.10it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 618.40it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 618.51it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 617.18it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 617.95it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 610.69it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 601.00it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 629.16it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 608.28it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 631.02it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 629.76it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 617.67it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 616.44it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 625.18it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 617.12it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 621.49it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 609.76it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 627.63it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 612.58it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 634.45it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 626.83it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 599.24it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 617.81it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 622.94it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 651.81it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 625.61it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 629.70it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 628.56it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 626.17it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 634.12it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 621.29it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 650.49it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 636.50it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 626.81it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 627.29it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 642.36it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 642.44it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 641.46it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 625.52it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 633.86it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 659.88it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 625.64it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 643.99it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 619.85it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 632.65it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 616.93it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 639.62it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 625.88it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 635.38it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 629.69it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 640.85it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 643.42it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 651.71it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 618.61it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 625.83it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 630.34it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 617.04it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 630.79it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 619.68it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 626.17it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 632.94it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 609.44it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 635.84it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 623.32it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 638.06it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 642.00it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 632.04it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 626.78it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 622.44it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 629.19it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 643.38it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 642.95it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 635.24it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 624.80it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 617.51it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 640.40it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 626.91it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 607.45it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 624.96it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 635.55it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 631.83it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 622.29it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 618.33it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 636.08it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 616.63it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 632.80it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 620.36it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 633.33it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 637.06it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 620.13it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 646.95it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 637.69it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 643.74it/s]\n",
            "100%|| 20000/20000 [00:32<00:00, 623.96it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 646.04it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 625.20it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 646.52it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 638.55it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 675.06it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 662.69it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.58it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 668.60it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 688.65it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.29it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.24it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 682.88it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 661.33it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 680.49it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 666.48it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 683.65it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 693.51it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 670.71it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 683.53it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 664.59it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 680.14it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 665.64it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 649.58it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 663.68it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 663.06it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 657.49it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 673.45it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 667.45it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.14it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 675.09it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 665.27it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 676.37it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 659.14it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 670.57it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 673.94it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 677.02it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.69it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 659.31it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 668.37it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 678.41it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 666.71it/s]\n",
            "100%|| 20000/20000 [00:33<00:00, 600.12it/s]\n",
            "100%|| 20000/20000 [00:36<00:00, 550.83it/s]\n",
            "100%|| 20000/20000 [00:35<00:00, 559.99it/s]\n",
            "100%|| 20000/20000 [00:35<00:00, 570.22it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 649.63it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 678.80it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 668.95it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 665.21it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 685.16it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 667.68it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 690.31it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 663.46it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 692.05it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 689.60it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 670.32it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 685.20it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 682.19it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.12it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 683.74it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 678.98it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 697.82it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 675.14it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 685.00it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 670.77it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 686.66it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 678.77it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 670.92it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 675.26it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 664.47it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 690.72it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 683.62it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.52it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 689.27it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 676.12it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 680.30it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 679.76it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 691.06it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 689.78it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 666.87it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 681.25it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 660.91it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 687.52it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 659.46it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 681.48it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 668.31it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 678.12it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 672.45it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 672.21it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 688.19it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 665.14it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 662.14it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 664.69it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 667.42it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 646.13it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 670.64it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 660.34it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 662.38it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 646.78it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 665.42it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 667.82it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 680.22it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 676.82it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 659.25it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 677.26it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 666.46it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 663.66it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 651.42it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.77it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 668.07it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 695.95it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 687.24it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 686.88it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 685.72it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 660.68it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 692.75it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.21it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 691.61it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 680.20it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 680.22it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 673.26it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 669.73it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 685.30it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.26it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 678.56it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.57it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 676.90it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 676.80it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 672.23it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 688.72it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.23it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 675.83it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 683.88it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.45it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 691.87it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 666.16it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 695.87it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 697.93it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 672.43it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 678.78it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 667.59it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 672.95it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 656.69it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 676.25it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 677.87it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 673.15it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 692.71it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 673.44it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 682.28it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 643.95it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 671.28it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 666.54it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 683.39it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 676.70it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 689.52it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.74it/s]\n",
            "100%|| 20000/20000 [00:31<00:00, 638.84it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.50it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 661.34it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 689.13it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 661.11it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 681.31it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 660.40it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 649.42it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 679.16it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 677.47it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 671.54it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 656.27it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 670.38it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 661.12it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 687.07it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 669.05it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.87it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 691.85it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 688.97it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 694.78it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 673.75it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.34it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.01it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 672.87it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 672.54it/s]\n",
            "100%|| 20000/20000 [00:28<00:00, 700.00it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 687.68it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 666.47it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 685.75it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 671.59it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 687.33it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 676.72it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 674.72it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 684.67it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 660.85it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 687.74it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 677.61it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 666.92it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 668.61it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 672.82it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 681.13it/s]\n",
            "100%|| 20000/20000 [00:30<00:00, 662.31it/s]\n",
            "100%|| 20000/20000 [00:29<00:00, 682.53it/s]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "# 2 actions\n",
        "ACTIONS = [0, 1]\n",
        "\n",
        "# each transition has a probability to terminate with 0\n",
        "TERMINATION_PROB = 0.1\n",
        "\n",
        "# maximum expected updates\n",
        "MAX_STEPS = 20000\n",
        "\n",
        "# epsilon greedy for behavior policy\n",
        "EPSILON = 0.1\n",
        "\n",
        "\n",
        "# break tie randomly\n",
        "def argmax(value):\n",
        "    max_q = np.max(value)\n",
        "    return np.random.choice([a for a, q in enumerate(value) if q == max_q])\n",
        "\n",
        "\n",
        "class Task:\n",
        "    # @n_states: number of non-terminal states\n",
        "    # @b: branch\n",
        "    # Each episode starts with state 0, and state n_states is a terminal state\n",
        "    def __init__(self, n_states, b):\n",
        "        self.n_states = n_states\n",
        "        self.b = b\n",
        "\n",
        "        # transition matrix, each state-action pair leads to b possible states\n",
        "        self.transition = np.random.randint(n_states, size=(n_states, len(ACTIONS), b))\n",
        "\n",
        "        # it is not clear how to set the reward, I use a unit normal distribution here\n",
        "        # reward is determined by (s, a, s')\n",
        "        self.reward = np.random.randn(n_states, len(ACTIONS), b)\n",
        "\n",
        "    def step(self, state, action):\n",
        "        if np.random.rand() < TERMINATION_PROB:\n",
        "            return self.n_states, 0\n",
        "        next_ = np.random.randint(self.b)\n",
        "        return self.transition[state, action, next_], self.reward[state, action, next_]\n",
        "\n",
        "\n",
        "# Evaluate the value of the start state for the greedy policy\n",
        "# derived from @q under the MDP @task\n",
        "def evaluate_pi(q, task):\n",
        "    # use Monte Carlo method to estimate the state value\n",
        "    runs = 1000\n",
        "    returns = []\n",
        "    for r in range(runs):\n",
        "        rewards = 0\n",
        "        state = 0\n",
        "        while state < task.n_states:\n",
        "            action = argmax(q[state])\n",
        "            state, r = task.step(state, action)\n",
        "            rewards += r\n",
        "        returns.append(rewards)\n",
        "    return np.mean(returns)\n",
        "\n",
        "\n",
        "# perform expected update from a uniform state-action distribution of the MDP @task\n",
        "# evaluate the learned q value every @eval_interval steps\n",
        "def uniform(task, eval_interval):\n",
        "    performance = []\n",
        "    q = np.zeros((task.n_states, 2))\n",
        "    for step in tqdm(range(MAX_STEPS)):\n",
        "        state = step // len(ACTIONS) % task.n_states\n",
        "        action = step % len(ACTIONS)\n",
        "\n",
        "        next_states = task.transition[state, action]\n",
        "        q[state, action] = (1 - TERMINATION_PROB) * np.mean(\n",
        "            task.reward[state, action] + np.max(q[next_states, :], axis=1))\n",
        "\n",
        "        if step % eval_interval == 0:\n",
        "            v_pi = evaluate_pi(q, task)\n",
        "            performance.append([step, v_pi])\n",
        "\n",
        "    return zip(*performance)\n",
        "\n",
        "\n",
        "# perform expected update from an on-policy distribution of the MDP @task\n",
        "# evaluate the learned q value every @eval_interval steps\n",
        "def on_policy(task, eval_interval):\n",
        "    performance = []\n",
        "    q = np.zeros((task.n_states, 2))\n",
        "    state = 0\n",
        "    for step in tqdm(range(MAX_STEPS)):\n",
        "        if np.random.rand() < EPSILON:\n",
        "            action = np.random.choice(ACTIONS)\n",
        "        else:\n",
        "            action = argmax(q[state])\n",
        "\n",
        "        next_state, _ = task.step(state, action)\n",
        "\n",
        "        next_states = task.transition[state, action]\n",
        "        q[state, action] = (1 - TERMINATION_PROB) * np.mean(\n",
        "            task.reward[state, action] + np.max(q[next_states, :], axis=1))\n",
        "\n",
        "        if next_state == task.n_states:\n",
        "            next_state = 0\n",
        "        state = next_state\n",
        "\n",
        "        if step % eval_interval == 0:\n",
        "            v_pi = evaluate_pi(q, task)\n",
        "            performance.append([step, v_pi])\n",
        "\n",
        "    return zip(*performance)\n",
        "\n",
        "\n",
        "def figure_8_8():\n",
        "    num_states = [1000, 10000]\n",
        "    branch = [1, 3, 10]\n",
        "    methods = [on_policy, uniform]\n",
        "\n",
        "    # average across 30 tasks\n",
        "    n_tasks = 30\n",
        "\n",
        "    # number of evaluation points\n",
        "    x_ticks = 100\n",
        "\n",
        "    plt.figure(figsize=(10, 20))\n",
        "    for i, n in enumerate(num_states):\n",
        "        plt.subplot(2, 1, i+1)\n",
        "        for b in branch:\n",
        "            tasks = [Task(n, b) for _ in range(n_tasks)]\n",
        "            for method in methods:\n",
        "                steps = None\n",
        "                value = []\n",
        "                for task in tasks:\n",
        "                    steps, v = method(task, MAX_STEPS / x_ticks)\n",
        "                    value.append(v)\n",
        "                value = np.mean(np.asarray(value), axis=0)\n",
        "                plt.plot(steps, value, label=f'b = {b}, {method.__name__}')\n",
        "        plt.title(f'{n} states')\n",
        "\n",
        "        plt.ylabel('value of start state')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.xlabel('computation time, in expected updates')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    figure_8_8()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}